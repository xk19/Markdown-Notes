之前的状态估计问题中已经说到了贝叶斯滤波的问题，提到噪声是高斯分布的线性系统的贝叶斯滤波其实就是卡尔曼滤波过程，也推导了一些公式，这里提供更加一般的表示和思想探讨。

## 贝叶斯学派思想

这里且不谈贝叶斯学派和概率学派的区别，仅使用概率学的知识来解决问题，即通过观测可以获取状态分布的信息，从而获取系统的概率分布。

## 贝叶斯滤波

状态估计问题的概率描述，需要对机器人当前时刻的状态$x_t$进行估计，使用外部的观测信息$z_t$，并且了解当前的输入$u_t$，那么状态估计问题描述成已知$1-t$时刻的输入$u_{1:t}$和观测$z_{1:t}$，求$t$时刻的状态$x_t$。

注意问题中的两个点：

1.问题中不仅有观测$z_t$也有输入$u_t$，这两个信息在贝叶斯滤波这里的地位是对等的，但是习惯将观测$z_t$放到前面来推导，是因为后面应用线性系统方程式时候输入$u_t$和观测$z_t$在概率中的地位有所差别，此时而对于两变量简单形式的贝叶斯公式$P(x|z)=\frac{P(z|x)P(x)}{P(z)}$，就不再相同，而是变成$P(x|z,u)$，这里的**逗号**是同时发生的意思，就变成了，
$$
P(x|z,u)=\frac{P(x)P(z|a)P(u|x,z)}{P(z)P(u|z)}
$$
这里还是强调**全概率公式**，
$$
P(x,z)=P(x|z)P(z)=P(z|x)P(x)
$$

$$
P(x,z,u)=P(u|x,z)P(z|x)P(x)
$$

用全概率公式再将$(z,u)$的联和概率再分解就能推导出上面的式子，值得注意的是后面的推导中，不仅有多变量的概率，还会将一系列概率事件拆开再进行推导，以实现自己的目的一定要善用全概率公式。

2.问题中的时刻，描述的是已知$1:t$时刻全部的输入$u_{1:t}$和状态$z_{1:t}$，求取的是当前时刻的状态$x_t$。这一段仅有贝叶斯概率思想的描述，没有对系统做后面我们熟知的充分的其他假设：线性系统、时不变系统，这些后来的假设是建立在系统建模的基础上考虑的，目前有的假设只是概率上的基本假设和系统现实意义的因果性质。

回到问题本身，问题就变成了计算一个**条件概率**，
$$
P(x_t|z_{1:t},u_{1:t})
$$
为了计算这个状态概率分布$x_t$，我们可以用$1-t$时刻所有观测$z_{1:t}$和输入$u_{1:t}$的概率分布计算将其解算出来，这甚至在生活中可以为我们提供指导，比如买西瓜，根据之前若干次买瓜的经验得到若干组西瓜的观测$z_{1:k}$和西瓜的状态$x_{1:k}$建立条件概率的方程就能解算出当前观测$z_m$的瓜的状态$x_m$的概率分布，用一个离散概率概率积分的公式即可，下次再买瓜的时候再将上一次的记录也添加进去，不断地买，理想下最终能得到完美的判断西瓜状态的系统。

每一时刻都进行如此复杂的积分是很耗时得的，最明智的做法就是**迭代**计算，此时我们加入**马尔可夫假设**，系统当前时刻的状态$x_{t}$只与上一个时刻状态$x_{t-1}$有关，与之前任意时刻的状态都没有关系。也表明，任意时刻的观测$z_t$仅仅和当前的状态$x_t$有关，而与其他观测$z_{1:t-1}$以及系统输入$u_{1：k}$无关。因此需要建立两个时刻之间的关系，将当前时刻的观测抽取出来：
$$
\begin{align}
bel(x_t)&=P(x_t|z_{1:t},u_{1:t}) \\
&=P(x_t|z_{t},z_{1:t-1},u_{1:t}) \\
\end{align}
$$
为了展开这个四变量的条件概率，写出全概率公式：
$$
\begin{align}
P(A,B,C,D)&=P(B,A,C,D) \\
&=P(A|B,C,D)P(B|C,D)P(C,D) \\
&=P(B|A,C,D)P(A|C,D)P(C,D)
\end{align}
$$
套进去就变成了
$$
\begin{align}
&P(x_t|z_t,z_{1:t-1},u_{1:t})P(z_t|z_{1:t-1},u_{1:t})P(z_{1:t-1},u_{1:t})\\
&=\\
&P(z_t|x_t,z_{1:t-1},u_{1:t})P(x_t|z_{1:t-1},u_{1:t})P(z_{1:t-1},u_{1:t})\\
\end{align}
$$
约去最后一个式子，就变成了
$$
\begin{align}
bel(x_t)&=P(x_t|z_{t},z_{1:t-1},u_{1:t})\\
&=\frac{P(z_t|x_t,z_{1:t-1},u_{1:t})P(x_t|z_{1:t-1},u_{1:t})}{P(z_t|z_{1:t-1},u_{1:t})}\\
&=\eta{P(z_t|x_t,z_{1:t-1},u_{1:t})P(x_t|z_{1:t-1},u_{1:t})}
\end{align}
$$
根据之前做过的马尔科夫假设，这个假设表示各个观测之间是独立，与之前的观测$z_{1:t-1}$无关，与系统输入$u_{1:k}$无关，因此上面的式子表述为：
$$
\begin{align}
bel(x_t)&=P(x_t|z_{t},z_{1:t-1},u_{1:t})\\
&=\eta{P(z_t|x_t)P(x_t|z_{1:t-1},u_{1:t})}
\end{align}
$$
将最后一项按照全概率公式展开，借助C-K公式，至于第一个式子如何转变为第二个式子，这里是C-K公式的用法，是在一系列有马尔可夫性质的状态$x_{1:n}$中寻求单步转移概率$P(x_n|x_{n-1},...,x_1)=P(x_n|x_{n-1})$以及多步转移概率用以替代联合概率$P(x_n,x_{n-1},...,x_1)$进行简化计算的方法，叫做Chapman-Kolmogorov公式，或者C-K公式，这里的多步的转移概率展开积分形式为$P(x_n|x_s)=\int{P(x_n|x_r)P(x_r|x_s)dx_r}$，这里的介绍仅限于此。
$$
\begin{align}
P(x_t|z_{1:t-1},u_{1:t})&=\int{P(x_t|x_{t-1},z_{1:t-1},u_{1:t})P(x_{t-1}|z_{1:t-1},u_{1:t})dx_{t-1}}
\end{align}
$$
然后根据马尔可夫的性质，这个式子简化为：
$$
\begin{align}
\bar{bel}(x_t)&=P(x_t|z_{1:t-1},u_{1:t})\\
&=\int{P(x_t|x_{t-1},u_{t})P(x_{t-1}|z_{1:t-1},u_{1:t})dx_{t-1}}
\end{align}
$$
那么根据上面几个公式就能得出：
$$
\begin{align}
bel(x_t) &= \eta{P(z_t|x_t)\bar{bel}(x_t)}\\
\bar{bel}(x_t)&=\int{P(x_t|x_{t-1},u_t)}bel(x_{t-1})dx_{t-1}
\end{align}
$$
于是，在应用贝叶斯滤波时候，首先根据具体的传感器类型确定$P(z_t|x_t)$和$P(x_t|x_{t-1},u_t)$，然后执行**预测**+**更新**两个步骤即可得到当前状态下的状态估计。

## 卡尔曼滤波

 在实际的应用中，复杂的$P(z_t|x_t)$和$P(x_t|x_{t-1},u_t)$使得计算难以进行，尤其是还有一个积分过程，卡尔曼滤波在**高斯噪声**+**线性系统**的前提下提了解决方案：

在卡尔曼滤波中，系统的状态和观测有两个方程，分别叫**状态方程**和**观测方程**：
$$
\begin{cases}
x_t=A_tx_{t-1}+B_tu_t+\epsilon_t,\epsilon_t\sim{N}(0,R_t)\\
z_t=C_tx_t+\delta_t,\delta_t\sim{N}(0,Q_t)
\end{cases}
$$
其中$\epsilon_t$是均值为零，方差为$R_t$的高斯随机噪声，$\delta_t$是均值为零，方差为$Q_t$的高斯随机噪声，那么用这种建模表示前面的两个概率分布为：
$$
\begin{align}
P(x_t|x_{t-1},u_t)&=
\frac{1}{\sqrt{|2{\pi}R_t|}}
e^{-\frac{1}{2}(x_t-A_tx_{t-1}-B_tu_t)^TR^{-1}_t(x_t-A_tx_{t-1}-B_tu_t)} \\
P(z_t|x_t)&=\frac{1}{\sqrt{|2{\pi}Q_t|}}
e^{-\frac{1}{2}(z_t-C_tx_t)^TQ^{-1}_t(z_t-C_tx_t)} 
\end{align}
$$
然后讲这两个式子带入到之前的两个步骤中，**预测**：
$$
\begin{align}
\bar{bel}(x_t)&=
\int{P(x_t|x_{t-1},u_t)}bel(x_{t-1})dx_{t-1} \\
&=\int{\frac{1}{\sqrt{|2{\pi}R_t|}}e^{-\frac{1}{2}(x_t-A_tx_{t-1}-B_tu_t)^TR^{-1}_t(x_t-A_tx_{t-1}-B_tu_t)}}
\frac{1}{\sqrt{|2{\pi}{\Sigma}_t|}}e^{-\frac{1}{2}(x_{t-1}-\mu_{t-1})^T\Sigma^{-1}_t(x_{t-1}-\mu_{t-1})}
dx_{t-1} \\
&=\eta{\int{e^{ -\frac{1}{2} ( (x_t-A_tx_{t-1}-B_tu_t)^TR^{-1}_t(x_t-A_tx_{t-1}-B_tu_t) +  (x_{t-1}-\mu_{t-1})^T\Sigma^{-1}_t(x_{t-1}-\mu_{t-1}) )  }}}dx_{t-1} \\
&=\eta\int{e^{ -\frac{1}{2}L_t} }dx_{t-1}
\end{align}
$$
其中新定义的这个高斯分布是属于上一状态$x_{t-1}$的，其均值为$\mu_{t-1}$，方差为$\Sigma_{t-1}$，然后上式将指数合并。

其中$L_t$：
$$
L_t=
(x_t-A_tx_{t-1}-B_tu_t)^TR^{-1}_t(x_t-A_tx_{t-1}-B_tu_t)
+
(x_{t-1}-\mu_{t-1})^T\Sigma^{-1}_t(x_{t-1}-\mu_{t-1})
$$
这里要求这个积分很难，可以尝试使用概率密度的性质来求，概率密度函数在定义域上的基本为1，如果将上面的式子表示为一个概率密度函数就好求了，上面的积分是指数函数的积分，质数部分是积分变量的二次型，比较满足高斯概率密度的特点，事实上$L_t$可以表示成：
$$
L_t = (x-\mu)^T\Sigma^{-1}(x-\mu)+b
$$
这种更一般的形式，为了到达这种形式，可以通过凑配，对于二次函数来说，配方的目的是将二次函数变成$y=a(x-h)^2+k$的形式，其中$2a$是曲率，$h$是极值点，$k$是极值。对于上面的式子，配方出的$\mu$是极值点，$b$是极值，$\Sigma^{-1}$是曲率。首先对$L_t$求导获取极值点和极值，再对$L_t$求二次导数获取曲率，求导的结果是：
$$
\begin{align}
\frac{\partial{L_t}}{\partial{x_{t-1}}}
&=-A^T_tR^{-1}_t(x_t-A_tx_{t-1}-B_tu_t)+\Sigma^{-1}_{t-1}(x_{t-1}-\mu_{t-1}) \\
\frac{\partial^2{L_t}}{\partial{x^2_{t-1}}}
&=A^T_tR^{-1}_tA_t+\Sigma^{-1}_{t-1}=\Psi^{-1}_t
\end{align}
$$
其中$\Psi^{-1}_t$为$L_t$的曲率，令一阶导数为零：
$$
x_{t-1}=\Psi_t(A^T_tR_t^{-1}(x_t-B_tu_t)+\Sigma^{-1}_{t-1}\mu_{t-1})
$$
得到极值、极值点、曲率之后重写$L_t$这个式子：
$$
\begin{align}
&L_t\\
&=(x_{t-1}-\Psi_t(A^T_tR_t^{-1}(x_t-B_tu_t)+\Sigma^{-1}_{t-1}\mu_{t-1}))^T\Psi^{-1}_t(x_{t-1}-\Psi_t(A^T_tR_t^{-1}(x_t-B_tu_t)+\Sigma^{-1}_{t-1}\mu_{t-1}))\\
&+(x_t-B_tu_t-A_t\mu_{t-1})^T(A_t\Sigma_{t-1}A^T_t+R_t)^{-1}(x_t-B_tu_t-A_t\mu_{t-1})
\end{align}
$$
如此操作后将与$x_{t-1}$的常数项无关的项提出去，得到
$$
\begin{align}
\bar{bel}(x_t)&=
\eta{ e^{ -\frac{1}{2}(x_t-B_tu_t-A_t\mu_{t-1})^T(A_t\Sigma_{t-1}A^T_t+R_t)^{-1}(x_t-B_tu_t-A_t\mu_{t-1})  } }
\end{align}
$$
在**预测**的过程中这个式子仍然是一个高斯分布的概率密度函数，均值和方差为：
$$
\begin{align}
\bar\mu_{t}&=A_t\mu_{t-1}+B_tu_t \\
\bar\Sigma_t&=A_t\Sigma_{t-1}A^T_t+R_t
\end{align}
$$
然后预测的部分就通过这个式子进行计算就OK了。

第二步就是**更新**：
$$
\begin{align}
&bel(x_t)=\\
&\eta{\frac{1}{\sqrt{2\pi{{Q_t}}}}e^{ -\frac{1}{2}(z_t-C_tx_t)^TQ^{-1}_t(z_t-C_tx_t) } 
e^{-\frac{1}{2} (x_t-B_tu_t-A_t\mu_{t-1})^T(A_t\Sigma_{t-1}A^T_t+R_t)^{-1}(x_t-B_tu_t-A_t\mu_{t-1}) }}
\end{align}
$$
关于上式子，依旧可以整理成一个标准的二次型，同之前预测的过程一样，这里就不整理了，直接写出最终得到的新的高斯分布的参数：
$$
\begin{align}
bel(x_t)&=\eta{ e^{ -\frac{1}{2}(x_t-\mu_t)^T\Sigma^{-1}_t(x_t-\mu_t) } } \\ 
\mu_t&=\bar\mu_t+K_t(z_t-C_t\bar\mu_t)\\
\Sigma_t&=(I-K_tC_t)\bar\Sigma_t\\
K_t&=\bar\Sigma_tC^T_t(C_t\bar\Sigma_tC_t^T+Q_t)^{-1}
\end{align}
$$
至此推导完毕，实际使用的时候，状态变量始终是高斯分布，只需要计算均值和协方差就行。

## 卡尔曼滤波的使用

#### 系统方程

$$
\begin{cases}
x_t=A_tx_{t-1}+B_tu_t+\epsilon_t,\epsilon_t\sim{N}(0,R_t)\\
z_t=C_tx_t+\delta_t,\delta_t\sim{N}(0,Q_t)
\end{cases}
$$

#### 0.设置初值

初始状态$x_0$，初始误差协方差$p_0$

#### 1.预测状态，预测协方差——预测

$\bar{x}_k=Ax_{k-1}+Bu_{k-1}$

$\bar{p}_k=A p_{k-1}A^T+Q$

#### 2.计算卡尔曼增益$K$——调整

$K_k=\bar{p}_k C^T (C\bar{p}_k C^T+R)^{-1}$

#### 3.根据观测计算状态，更新协方差——修正

${x}_k=\bar{x}_k+K_k(z_k-C\bar{x}_k)$

$p_k=\bar{p}_k - K_k C \bar{p}_k$

上面的每一个变量都很重要，并在实际系统中有可能是高维度的，有可能是紧凑的，也可能是稀疏的，仔细理解每个变量的意义：

其中$A$和$B$是状态方程中重要的函数，在非线性系统中则表述为$x_k=F(x_{k-1},u_k)+\epsilon_t$。

经常用F这个字母来表示系统中的状态方程，用G或者H来代表系统中的观测方程C。P一般用于表示协方差矩阵，K则代表卡尔曼增益。

协方差矩阵的作用是：利用P协方差生成卡尔曼增益以在预测和修正中传递置信信息。

预测的理解是：预测的两个步骤分别代表了均值和协方差的预测，这个预测是根据系统方程的预测。

调整的理解是：根据协方差生成的卡尔曼增益仅仅用到了协方差本身和观测方程。

修正的理解是：修正体现出滤波的思想，修正的两步分别对状态和协方差修正1.对于系统方程预测的状态和观测的状态根据卡尔曼增益加权2.对于系统方程预测的协方差和观测的协方差根据卡尔曼增益加权。最终体现出卡尔曼滤波是在系统建模和输入观测之间做加权平均。

紧凑的状态方程，有利于系统中变量的维度更小，



### GPS定位例子建模

机器人从原点出发，采样周期$T$，用$x_k$表示机器人的在采样时间点$k T$处的位置，用$z_k$表示该时刻的GPS观测值，输入是机器人的加速度$a_k$，那么观测方程为$z_k=x_k+v_k$，那么系统的状态方程为$x_{k+1}=x_k+v_kT+\frac{1}{2}a_kT^2$，状态方程的导数求速度的方程$v_{k+1}=v_k+Ta_k$，得到系统方程为：
$$
\begin{cases}
\begin{bmatrix}
x_{k+1}\\
v_{k+1}
\end{bmatrix}
=
\begin{bmatrix}
1&T\\
0&1
\end{bmatrix}
\times
\begin{bmatrix}
x_{k}\\
v_{k}
\end{bmatrix}
+
\begin{bmatrix}
0.5T\\
T
\end{bmatrix}
\times
a_k
+
\begin{bmatrix}
0.5T\\
T
\end{bmatrix}
\times
e_k \\
z_k
=
\begin{bmatrix}
1&0
\end{bmatrix}
\times
\begin{bmatrix}
x_{k}\\
v_{k}
\end{bmatrix}
+
q_k
\end{cases}
$$
其中系统参数$A=\begin{bmatrix}1&T\\0&1\end{bmatrix}$，$B=\begin{bmatrix}0.5T\\T\end{bmatrix}$，$C=\begin{bmatrix}1&0\end{bmatrix}$。

设置初值为$\begin{bmatrix}x_{0}=0\\v_{}=0\end{bmatrix}$，先验协方差矩阵为$p_o=\begin{bmatrix}1&0\\0&1\end{bmatrix}$。根据上面的步骤开始迭代即可。

在使用卡尔曼滤波时候，应至少保证系统模型或者系统测量至少一个有足够的精度，否则卡尔曼滤波无法从中提取正确的估计信息，卡尔曼滤波本身可以看作在先验模型和仪器测量值调整权重，若二者都不准确，那么估计值也会比较差。

## 其他卡尔曼滤波方法

### 拓展卡尔曼滤波EKF

传统卡尔曼滤波要求系统的状态方程和观测方程均是线性条件，然而现实中，许多工程系统往往不能简单地用线性系统来描述，如参数估计引入增广状态方程的非线性、结构关系带来的非线性和观测信号的非线性。因此，十分有必要对非线性滤波进行深入的讨论。一般情况是将非线性方程线性化，而后利用线性卡尔曼滤波基本方程处理线性问题。
$$
\begin{cases}
x_k=f(x_{k-1})+e\\
z_k=h(x_{k})+q
\end{cases}
$$
其中两个函数为非线性函数，在预测方程中，方程的参数使用泰勒展开一阶偏导来计算，不能像普通卡尔曼滤波一样离线计算参数。

### 自适应卡尔曼滤波AKF



###　无迹卡尔曼滤波UKF

对于非线性问题的处理，状态方程F和观测方程H是非线性的，EKF是求一阶全导数得到线性模型，来近似非线性模型；而UKF是直接寻找一个与真实分布近似的高斯分布，没有用线性表征。

精度优于EKF，相当于泰勒二阶展开，不需要计算雅可比矩阵，省去了求导过程，速度相对较慢，和PF很相似，UKF的粒子是固定的，PF的粒子是随机的并且不存在高斯假设适用于任意分布。



### Error-State卡尔曼滤波ESKF

在KF和EKF中，系统方程直接描述系统状态，不存在转化过程，是直接滤波法。而ESKF中系统方程描述系统误差，预测和更新都针对系统的误差状态，属于间接滤波。

本质上都属于贝叶斯滤波，和KF、EKF流程大体一致。

都基于马尔可夫性质。

KF、EKF是直接滤波方法，ESKF是间接滤波方法。

EKF用于非线性系统中，ESKF主要应用在管道系统中，KF只能用于线性系统。

EKF需要计算雅可比矩阵计算复杂度很高，ESKF次之，KF计算最快。

在ESKF系统中，系统误差的值一般很小接近0，可以避免一些一阶导数的奇点，如惯导系统中的万向锁，值比较小保证泰勒展开中的二次项忽略不计，使得雅可比计算更加快速甚至有些系统中雅可比矩阵可作常数，ESKF的系统动作都比较缓慢，因为有较大的成分集成在了normal-state上，可以使卡尔曼滤波的更新频率低于预测过程。

LINS是IESKF，FAST-LIO是IESKF。

预测都是基于IMU进行预测，对于点云补偿畸变也是用IMU数据，预测公式就是一个刚体运动模型，包括旋转和平移，这里不能简单看作加速度模型，应该描述为刚体运动模型。

更新部分对于IKF来说，就是一个优化问题，首先观测方程就是LOAM中的观测方程，对于这个优化问题进行迭代求解，就用高斯牛顿法来迭代优化过程，然后得到优化后的位姿的结果，这里的H就是状态方程的雅可比，然后根据H计算卡尔曼增益，根据卡尔曼增益完成最后的预测和优化结果的滤波过程。计算卡尔曼增益时间比较困难的事情，计算点对之前的匹配误差来计算雅可比没啥问题，关键是这会是H矩阵的维度变大，卡尔曼增益K的维度也变大，然后FAST-LIO中对增益求逆的公式做了简化，使得计算出来的K维度仅仅取决于误差状态的维度而不是观测的维度。



### 迭代卡尔曼滤IKF

IKF作为KF的变体，和EKF一样，主要是为了解决非线性问题，精度上IKF比EKF要好一点，其他的迭代卡尔曼滤波和IKF基本使相同的思路。

IKF的贡献主要是在更新阶段，使用gauss-newton的方法进行迭代，不断更新状态量。





